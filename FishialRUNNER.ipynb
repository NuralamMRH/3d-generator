{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NuralamMRH/3d-generator/blob/main/FishialRUNNER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "PCZ8KEwbixeL"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import copy\n",
        "import random\n",
        "import json\n",
        "import yaml\n",
        "import glob\n",
        "import cv2\n",
        "import numpy as np\n",
        "import time\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import requests\n",
        "from   zipfile import ZipFile\n",
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "import logging\n",
        "import torch\n",
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(level=logging.INFO)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def download_and_unzip(url, save_path, extract_dir):\n",
        "    print(\"Downloading assets...\")\n",
        "    file = requests.get(url)\n",
        "\n",
        "    open(save_path, \"wb\").write(file.content)\n",
        "    print(\"Download completed.\")\n",
        "\n",
        "    try:\n",
        "        if save_path.endswith(\".zip\"):\n",
        "            with ZipFile(save_path, 'r') as zip_ref:\n",
        "                zip_ref.extractall(extract_dir)\n",
        "            print(\"Extraction Done\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "def download_image(url):\n",
        "    filename = os.path.basename(url)\n",
        "\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()\n",
        "\n",
        "    with open(filename, 'wb') as file:\n",
        "        file.write(response.content)\n",
        "\n",
        "    return os.path.abspath(filename)\n",
        "\n",
        "def get_basename(path):\n",
        "  return os.path.basename(path)\n",
        "\n",
        "def print_fish_data(fish_data):\n",
        "    for idx, fish in enumerate(fish_data, start=1):\n",
        "        print(f\"ID: {idx}\")\n",
        "        print(f\"Name: {fish['name']}\")\n",
        "        print(f\"Species ID: {fish['species_id']}\")\n",
        "        print(f\"Distance: {fish['distance']:.3f}\")\n",
        "        print(f\"Accuracy: {fish['accuracy']:.2%}\")\n",
        "        print(\"-\" * 40)\n"
      ],
      "metadata": {
        "id": "loazHHM0i5bs"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Links to models\n",
        "MODEL_URLS = {\n",
        "    'classification': 'https://storage.googleapis.com/fishial-ml-resources/classification_rectangle_v7-1.zip',\n",
        "    'segmentation': 'https://storage.googleapis.com/fishial-ml-resources/segmentator_fpn_res18_416_1.zip',\n",
        "    'detection': 'https://storage.googleapis.com/fishial-ml-resources/detector_v10_m3.zip',\n",
        "    'face': 'https://storage.googleapis.com/fishial-ml-resources/face_yolo.zip'\n",
        "}\n",
        "\n",
        "# Model directories\n",
        "MODEL_DIRS = {\n",
        "    'classification': \"models/classification\",\n",
        "    'segmentation': \"models/segmentation\",\n",
        "    'detection': \"models/detection\",\n",
        "    'face': \"models/face_detector\"\n",
        "}\n",
        "\n",
        "# Create directories and download models\n",
        "for model_name, url in MODEL_URLS.items():\n",
        "    model_dir = MODEL_DIRS[model_name]\n",
        "    zip_path = os.path.join(os.getcwd(), get_basename(url))\n",
        "\n",
        "    os.makedirs(model_dir, exist_ok=True)  # Create directory if it doesn't exist\n",
        "    download_and_unzip(url, zip_path, model_dir)  # Download and unzip the model\n",
        "\n",
        "    # Remove the zip file after extraction\n",
        "    try:\n",
        "        os.remove(zip_path)\n",
        "        logging.info(f\"Removed zip file {zip_path}\")\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Failed to remove zip file {zip_path}: {e}\")"
      ],
      "metadata": {
        "id": "4Wi-1is8i9ME",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0e400e4-4e27-4e90-95f8-1a6cf808e8b1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading assets...\n",
            "Download completed.\n",
            "Extraction Done\n",
            "Downloading assets...\n",
            "Download completed.\n",
            "Extraction Done\n",
            "Downloading assets...\n",
            "Download completed.\n",
            "Extraction Done\n",
            "Downloading assets...\n",
            "Download completed.\n",
            "Extraction Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from models.classification.inference import EmbeddingClassifier\n",
        "from models.detection.inference import YOLOInference\n",
        "from models.segmentation.inference import Inference\n",
        "from models.face_detector.inference import YOLOInference as FaceInference\n",
        "\n",
        "\n",
        "# Model initialization\n",
        "classifier = EmbeddingClassifier(\n",
        "    os.path.join(MODEL_DIRS['classification'], 'model.ts'),\n",
        "    os.path.join(MODEL_DIRS['classification'], 'database.pt')\n",
        ")\n",
        "\n",
        "segmentator = Inference(\n",
        "    model_path=os.path.join(MODEL_DIRS['segmentation'], 'model.ts'),\n",
        "    image_size=416\n",
        ")\n",
        "\n",
        "detector = YOLOInference(\n",
        "    os.path.join(MODEL_DIRS['detection'], 'model.ts'),\n",
        "    imsz=(640, 640),\n",
        "    conf_threshold=0.9,\n",
        "    nms_threshold=0.3,\n",
        "    yolo_ver='v10'\n",
        ")\n",
        "\n",
        "face_detector = FaceInference(\n",
        "    os.path.join(MODEL_DIRS['face'], 'model.ts'),\n",
        "    imsz=(640, 640),\n",
        "    conf_threshold=0.69,\n",
        "    nms_threshold=0.5,\n",
        "    yolo_ver='v8'\n",
        ")"
      ],
      "metadata": {
        "id": "gF8o3tD_4byw"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# You can change link below to your image with fish\n",
        "url = 'https://www.mdpi.com/fishes/fishes-08-00514/article_deploy/html/images/fishes-08-00514-g001.png'\n",
        "url_face = 'https://www.online-tech-tips.com/wp-content/uploads/2022/02/faces.jpeg'\n",
        "face_path = download_image(url_face)\n",
        "fish_path = download_image(url)"
      ],
      "metadata": {
        "id": "_SDpjmSqlB9o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "outputId": "6b0ca491-e1f1-404d-8b9c-fcebbd79217f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "HTTPError",
          "evalue": "403 Client Error: Forbidden for url: https://www.mdpi.com/fishes/fishes-08-00514/article_deploy/html/images/fishes-08-00514-g001.png",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-19-3772022292.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0murl_face\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'https://www.online-tech-tips.com/wp-content/uploads/2022/02/faces.jpeg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mface_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_face\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mfish_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-16-3781613536.py\u001b[0m in \u001b[0;36mdownload_image\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: 403 Client Error: Forbidden for url: https://www.mdpi.com/fishes/fishes-08-00514/article_deploy/html/images/fishes-08-00514-g001.png"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "face_bgr_np = cv2.imread(face_path)\n",
        "face_rgb_np = cv2.cvtColor(face_bgr_np, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "face_boxes = face_detector.predict(face_rgb_np)[0]\n",
        "\n",
        "for box in face_boxes:\n",
        "  box.draw_label(face_rgb_np, \"Face\")\n",
        "  box.draw_box(face_rgb_np)\n",
        "plt.imshow(face_rgb_np)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "feUaaxwQEUb1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fish_bgr_np = cv2.imread(fish_path)\n",
        "visulize_img_bgr = fish_bgr_np.copy()\n",
        "\n",
        "visulize_img_rgb = cv2.cvtColor(fish_bgr_np, cv2.COLOR_BGR2RGB)\n",
        "visulize_img = copy.deepcopy(visulize_img_rgb)\n",
        "\n",
        "\n",
        "face_boxes = face_detector.predict(visulize_img_rgb)[0]\n",
        "\n",
        "for box in face_boxes:\n",
        "  box.draw_label(visulize_img, \"Face\")\n",
        "  box.draw_box(visulize_img)\n",
        "plt.imshow(visulize_img)\n",
        "plt.show()\n",
        "\n",
        "boxes = detector.predict(visulize_img_rgb)[0]\n",
        "\n",
        "for box in boxes:\n",
        "  cropped_fish_bgr = box.get_mask_BGR()\n",
        "  cropped_fish_rgb = box.get_mask_RGB()\n",
        "  segmented_polygons = segmentator.predict(cropped_fish_bgr)[0]\n",
        "\n",
        "  croped_fish_mask = segmented_polygons.mask_polygon(cropped_fish_rgb)\n",
        "\n",
        "  segmented_polygons.move_to(box.x1, box.y1)\n",
        "  segmented_polygons.draw_polygon(visulize_img)\n",
        "\n",
        "  classification_result = classifier.batch_inference([cropped_fish_bgr])[0]\n",
        "\n",
        "  label = f\"{classification_result[0]['name']} | {round(classification_result[0]['accuracy'], 3)}\" if len(classification_result) else \"Not Found\"\n",
        "  box.draw_label(visulize_img, label)\n",
        "  box.draw_box(visulize_img)\n",
        "\n",
        "  print(50 * \"=\")\n",
        "  plt.imshow(croped_fish_mask)\n",
        "  plt.show()\n",
        "  print_fish_data(classification_result)\n",
        "plt.imshow(visulize_img)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AiCKu1YimtHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FU"
      ],
      "metadata": {
        "id": "uxUjL4J071M5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import cv2\n",
        "\n",
        "# Image Load\n",
        "face_bgr_np = img = cv2.imread(face_path)\n",
        "face_rgb_np = cv2.cvtColor(face_bgr_np, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "fish_bgr_np = cv2.imread(fish_path)\n",
        "fish_rgb_np = cv2.cvtColor(fish_bgr_np, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "times_array = []\n",
        "for _ in range(3):\n",
        "  start_time_complex = time.time()\n",
        "  print(20 * \"=\")\n",
        "  start_time = time.time()\n",
        "  face_boxes = face_detector.predict(face_bgr_np)[0]\n",
        "  end_time = time.time()\n",
        "  print(f\"Face detection time: {end_time - start_time:.4f} seconds\")\n",
        "\n",
        "  start_time = time.time()\n",
        "  boxes = detector.predict(fish_bgr_np)[0]\n",
        "  end_time = time.time()\n",
        "  print(f\"Fish detection time: {end_time - start_time:.4f} seconds\")\n",
        "\n",
        "  # Обработка каждого объекта\n",
        "  for box in boxes:\n",
        "      cropped_fish_bgr = box.get_mask_BGR()\n",
        "\n",
        "      # Segmentation\n",
        "      start_time = time.time()\n",
        "      segmented_polygons = segmentator.predict(cropped_fish_bgr)[0]\n",
        "      end_time = time.time()\n",
        "      print(f\"Segmentation time: {end_time - start_time:.4f} seconds\")\n",
        "\n",
        "      # Classification\n",
        "      start_time = time.time()\n",
        "      classification_result = classifier.batch_inference([cropped_fish_bgr])[0]\n",
        "      end_time = time.time()\n",
        "      print(f\"Classification time: {end_time - start_time:.4f} seconds\")\n",
        "  times_array.append(time.time() - start_time_complex)\n",
        "\n",
        "print(f\"Average time: {sum(times_array)/len(times_array)}\")"
      ],
      "metadata": {
        "id": "FQS8xfOd7clr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Face detection time execution test without postprocessing"
      ],
      "metadata": {
        "id": "p_hhq9JLCnun"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 10\n",
        "start_time = time.time()\n",
        "face_detector.model(torch.randn(BATCH_SIZE,3,640,640))\n",
        "print(f\"Mean face detection total time (Batch): {(time.time() - start_time)} seconds\")"
      ],
      "metadata": {
        "id": "9gHEVdSSCn2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fish detection time execution test without postprocessing"
      ],
      "metadata": {
        "id": "eA22gY_zBzQ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 1\n",
        "start_time = time.time()\n",
        "detector.model(torch.randn(BATCH_SIZE,3,640,640))\n",
        "print(f\"Mean fish detection total time (Batch): {(time.time() - start_time)} seconds\")\n"
      ],
      "metadata": {
        "id": "Xk4uYVSYBKl1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fish Segmentation time execution test without postprocessing"
      ],
      "metadata": {
        "id": "Dcdq3WP_CBuN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 5\n",
        "start_time = time.time()\n",
        "segmentator.model(torch.randn(BATCH_SIZE,3,416,416))\n",
        "print(f\"Fish segmentation total time (Batch): {(time.time() - start_time)} seconds\")"
      ],
      "metadata": {
        "id": "AKfQ8YwBCB2b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fish Classification time execution test without postprocessing"
      ],
      "metadata": {
        "id": "P0RdNm-hCVLA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 5\n",
        "start_time = time.time()\n",
        "classifier.model(torch.randn(BATCH_SIZE,3,224,224))\n",
        "print(f\"Fish Classification total time (Batch): {(time.time() - start_time)} seconds\")"
      ],
      "metadata": {
        "id": "Yryw2NEiCVQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "NJdgqu3vrCYy"
      }
    }
  ]
}